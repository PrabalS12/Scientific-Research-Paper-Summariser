{
	"Title": "Distributed denial of service attack detection using an ensemble of neural classifier",
	"Abstract": "The vulnerabilities in the Communication (TCP/IP) protocol stack and the availability of more sophisti- cated attack tools breed in more and more network hackers to attack the network intentionally or unin- tentionally, leading to Distributed Denial of Service (DDoS) attack. The DDoS attacks could be detected using the existing machine learning techniques such as neural classifiers. These classifiers lack general- ization capabilities which result in less performance leading to high false positives. This paper evaluates the performance of a comprehensive set of machine learning algorithms for selecting the base classifier using the publicly available KDD Cup dataset. Based on the outcome of the experiments, Resilient Back Propagation (RBP) was chosen as base classifier for our research.The improvement in performance of the RBP classifier is the focus of this paper.Our proposed classification algorithm, RBPBoost, is achieved by combining ensemble of classifier outputs and Neyman Pearson cost minimization strategy, for final classification decision. Publicly available datasets such as KDD Cup, DARPA 1999, DARPA 2000, and CONFICKER were used for the simulation experiments. RBPBoost was trained and tested with DARPA, CONFICKER, and our own lab datasets. Detection accuracy and Cost per sample were the two metrics evaluated to analyze the performance of the RBPBoost classification algorithm.From the simulation results, it is evident that RBPBoost algorithm achieves high detection accuracy (99.4%) with fewer false alarms and outperforms the existing ensemble algorithms. RBPBoost algorithm outperforms the existing algorithms with maximum gain of 6.6% and minimum gain of 0.8%. Ó2011 Elsevier B.V. All rights reserved.",
	"1. Introduction": "DDoS is a coordinated attack on the availability of services of a single or multiple victim systems through many compromised sec- ondary victims. One such massive attack[20]happened at yahoo. com website on February 7, 2000. Similar attacks were reported in other commercial organizations[20]such as cnn.com, e-bay, Amazon, etc. Yet another attack, the slammer worm[46]– its virulent propagation resulted in the shutdown of range of critical systems including a safety monitoring system in Ohio, thousands of automatic teller machines run by the Bank of America, and the Internet share trading in South Korea. Even after a decade, since its first attack in 1998, Internet is still vulnerable to DDoS attack. A survey by Arbor Networks[9]on November 11, 2008, revealed that the scale of DDoS attacks has been growing gradually since",
	"2001. In 2008, the largest recorded DDoS attacks against a single": "target reached 40 gigabits per second, as against 24 gigabits reported in the year 2007. Hence, DDoS attacks are the most signif- icant security threat that ISPs face. The typical collaborative applications[14,49,62]in India, include the Space research, Military applications, Higher learning in Universities and Satellite campuses, State and Central government sponsored projects, e-governance, e-healthcare systems, etc. These applications/projects have inherently geographically distributed centers carrying out specific task/research, networked together to achieve the common goal. Any attack on data or the process in any one of the centers disrupts the objective. Hence, these critical infrastructure and services need protection. Revenue loss, Network performance degradation, and Service unavailability at critical time are some of the factors that motivated us to provide protection for these collaborative applications. DDoS attacks such as IRC flood, HTTP flood, SYN flood, UDP flood, and buffer overflow have been posing a serious threat[20]to such resource centers. A defensive strategy that understands the semantics and flow of service messages is required for detecting attacks. When a service is flooded with a volume of messages that exceeds its processing capacity, the excess must be discarded. The packet based discard strategy which distinguishes legitimate messages (flash crowd) from flood traffic is used to circumvent the impact on legitimate service requesters. The patterns of network traffic do not have a regular structure, and hence the statistical pattern recognition approaches are needed. As the Internet is administered in a distrib- uted environment, existing defense and response systems suffer cooperation between networks. Due to massive flooded traffic, available resources are not sufficient enough to mitigate an attack. On detection of an attack, a node exchanges its list of infected nodes with the other collaborative nodes for prevention of further 0140-3664/$ - see front matterÓ2011 Elsevier B.V. All rights reserved. doi:10.1016/j.comcom.2011.01.012 ⇑ Corresponding author. Tel.: +91 431 2503239; fax: +91 431 2500133. E-mail addresses:park@nitt.edu(P.A. Raj Kumar),ssk@nitt.edu(S. Selvakumar). Computer Communications 34 (2011) 1328–1341 Contents lists available atScienceDirect Computer Communications journal homepage: www.elsevier.com/locate/comcom attacks in other nodes as well.In this paper, a generic architecture for the automatic detection of DDoS attacks and response appliance that is aware of the semantics and flow of service messages is pro- posed. Our proposed system differs from[18,42]in alert generation strategy using ensemble of classifiers, but similar in communicat- ing the attack signatures by the peers in the collaborative environ- ment. Our proposal is to make intelligent message discard decisions based on Neural Networks to result in fewer false alarms. The contributions of this paper include the following: \u0002Generic architecture of DDoS attack detection and response sys- tem for collaborative environment. \u0002Implementation of RBPBoost algorithm for the classification of network traffic. \u0002Classification error cost Minimization by Neyman Pearson – Structural Risk Minimization. \u0002A classification accuracy of – 97.2% when training and testing on the conficker dataset. – 98.5% when training and testing on the lab dataset. – 99.4% when training and testing on the 1999 and 2000 DAR- PA Intrusion dataset. The rest of the paper is organized as follows: DDoS attack char- acteristics are given in Section2.1. Existing feature extraction methods are given in Section2.2. Machine learning methods for DDoS attack detection are given in Section2.3. Soft Computing techniques for intrusion detection are given in Section2.4. Existing traceback mechanisms are explained in Section2.5. Existing ensemble of classifier methods are given in Section2.6. Proposed DDoS attack detection and response system are elucidated in Sec- tion3. Simulation experiment details and the results are given in Section4. Section5concludes the paper.",
	"2.1. DDoS attack": "DDoS attack is broadly classified into bandwidth depletion and resource depletion attack[58]. In bandwidth depletion attack, attackers flood the victim with large traffic that prevents the legit- imate traffic and amplify the attack by sending messages to broad- cast IP address. In resource depletion attack, attackers attempt to tie up the critical resources (memory and processor) making the victim unable to process the service. A structural approach for DDoS attack classification is proposed in[27]. The detailed analysis on DDoS attacks and available attack tools[10]show that the DDoS attack has the following characteristics: \u0002Source and Destination IP address and port numbers of the packets are spoofed and randomly generated. \u0002Window size, sequence number, and packet length are fixed during the attack. \u0002Flags in the TCP and UDP protocols are manipulated. \u0002Roundtrip time is measured from the server response. \u0002Routing table of a host or gateway is changed. \u0002DNS transaction IDs (reply packet) are flooded. \u0002HTTP requests are flooded through port 80. Real Challenge lies in distinguishing the flooding attacks from abrupt change in legitimate traffic. For example, Flashget[30]on a host (specific IP address) creates a large number of connections using multiple source ports to a single destination port of a server for downloading a file. This behavior is similar to that of SYN flood. However, the difference between SYN flood and Flashget is that the SYN flood will not complete the TCP 3-way handshakes with the target victim within the specified time period leading to a lot of SYN errors. Further, many P2P file sharing applications use a single source port to connect to a lot of destination IP addresses for sharing files. This looks similar to a host scan activity. Flash crowd refers to more number of clients with less number of requests. But, DDoS attack is generated by less number of clients each generating a huge request traffic rate. Thus, the features such as number of connec- tions from the same host to the specific destination within the specified time window and number of connections having SYN errors within the specified time window could be seen to differentiate the flooding attacks from abrupt changes of legitimate activity. Attacks such as quiet attack[6], low rate TCP Denial of Service (DoS) attack[4], and Reduction of Quality (RoQ) attacks[5,67]are short lived TCP flows. Only less than 2% of the internet traffic are short lived flows. One third of the flows of internet traffic are long lived flows. Shrew[6]and RoQ attacks send high rate UDP traffic periodically. As feature such as a number of UDP echo packets to a specified port is used in our paper, shrew and RoQ attacks can be detected. In quiet attack, because of aggregated attack traffic rate, link capacity is under attack. Our proposed work has not con- sidered about the quiet attacks. But, quiet attack can be detected by monitoring the periodicity of burst rate in the flow.",
	"2.2. Real time feature extraction": "Features are statistical characteristics derived from the col- lected dataset. Selection of real time feature set plays a vital role in online traffic classification. More number of features lead to bet- ter accuracy. But, computation of more number of features in real time causes more overhead and time consuming. 248 features are given and 1 feature is used to describe the class (normal or attack) in[47]. Computation of all the 248 features[13]took approxi- mately two days on a dedicated System Area Network. Out of 248 features, some features such as maximum interpacket arrival time cannot be calculated until the entire flow is completed. More- over, features based on Fast Fourier Transform values need better signal processing methods to reduce the computation time. So, less number of appropriate statistical features is to be selected for bet- ter pattern classification. Feature extraction[36]is classified into two stages: (i) Feature Construction (ii) Feature Selection. Constructing the features is either integrated into the modeling process or into the preprocess- ing stage which includes standardization, normalization, etc. Fea- ture Selection is divided into Filter methods and wrapper methods[50]. In filter methods, selection is based on distance and information measures in the feature space. In wrapper meth- ods, selection is based on classifier accuracy. Three statistical fea- tures are used in[25]. Nine features are used in[35]. Flow based feature selection has been shown to block legitimate traffic in [35]. Flow based selection gives summary of metadata. By blocking the IP address and port, flow based selection does not permit the legitimate requests. Hence, instead of flow based solution, packet based solution has been used in this paper.Packet based solution minimizes the prevention of legal traffic as it blocks only the par- ticular traffic based on the outcome of the analysis of the sequence number, window size, and packet length. Features are selected by classifying the IP flow into micro-flow and macro-flow[26]. Deci- sion tree based Machine Learning (ML) algorithm combined with real time features has been proposed to be a good candidate for online traffic[69]. But, finding the smallest Decision Tree that is consistent with a set of training examples is NP-hard.",
	"2.3. Machine learning methods": "Machine learning is mostly focused on finding relationships in data and analyzing the process for extracting such relations. P.A. Raj Kumar, S. Selvakumar /Computer Communications 34 (2011) 1328–1341 1329 Machine learning paradigms are classified as Supervised Learning (SL), Unsupervised Learning (UL), and Reinforcement Learning (RL). In SL, the algorithm attempts to learn some function with gi- ven input vector and actual output. In UL, the algorithm attempts to learn only with given input vector by identifying relationships among data. In RL, the algorithm learns with a single bit of infor- mation which indicates to the neuron whether the output is good or bad.Though many evolutionary algorithms exist, neural network algorithms provide a promising alternative in classifying the DDoS at- tack patterns based on statistical features[45].Because of its gener- alization capability, neural networks are able to work with imprecise and incomplete data. Further, these machine learning techniques can also recognize the patterns not presented during a training phase. Several ML algorithms[25,35,54,59,63,64,66]have been proposed for DDoS attack detection. Most of the ML algo- rithms applied to DDoS attack detection have not considered min- imizing the cost of the errors. These errors lead to more false alarms. The cost associated with false alarm is more expensive than misdetection[23]. Hence, the objective in this paper is to minimize these errors and improve the false alarm rate. In this paper, the existing machine learning algorithms, viz., RBP[45], Support Vector Machine[48], K-Nearest Neighbor[32], Decision Tree (C4.5)[45], and K-Means Clustering[28]have been simulated (Section4) and the RBP algorithm is found to perform better. So, the RBP algorithm is chosen as Base Classifier in this paper, for further improvement in performance.",
	"2.4. Soft computing methods": "Recent network intrusion detection methods are based on soft computing techniques such as Neural Networks, Genetic algo- rithm, Fuzzy Logic, and hybrid approaches. Enhanced Swarm Intel- ligence Clustering (ESIC) method to choose the center of the radial basis function (RBF) in an RBF neural network (RBFNN) is proposed in[29].In[41], a genetic clustering algorithm for intrusion detec- tion is proposed and from the results, the optimal number of clus- ters and high performance rates are obtained. In[60], a method of incremental mining is proposed so that fuzzy association rules can be implemented in a real-time network IDS. Creation of fuzzy sets from the input network packet data, membership functions for fuz- zy variables, and the application of genetic algorithm to identify the best rules are proposed in[24].In[40], the Hidden Markov Model (HMM) is improved as fuzzy HMM (FHMM) where fuzzy similarity measures replaced probabilistic measures. The main drawback of soft computing methods is lack of interpretability [45]. Hybrid methods have been proposed to overcome the draw- backs of single methods. Of late, the research on intrusion detection is also towards using wavelets. Wavelet analysis is used for characterizing self-similar behavior, over a wide range of time scales. Wavelet neural network is based on the wavelet transform theory and the artificial neural network. In[37], intrusions are detected using wavelet neural net- works and their experimental results show that their proposed method is feasible and effective when tested with KDD Cup data- set. Selection of features from packet headers, comparing two rule sets, one mined online and the other mined from training data, rendering a decision every two seconds on large-scale DoS attack types are some of the tasks carried out in[37].",
	"2.5. Existing traceback mechanisms": "Once the target system is attacked, the detection mechanisms are necessary to detect an attack with less false positive rate and more accuracy rate. To foil the DDoS attacks, countermeasures such as detection mechanisms and traceback mechanisms can be deployed. Among these mechanisms, response system needs to identify the location of the source in order to prevent further attacks. The security expert spends time in tracing the real source address and at times it demands more time as the perpetrator spoofs the source IP address. Traceback mechanisms[1–3,7, 8,15,21,22,34,51,65,68,70,72]have been proposed to trace the real source of the attackers to stop the attack at the point nearest to its source in order to reduce waste of network resources and to find the identity of the attackers in order to take other legal actions against them. A detailed comparison of the existing traceback mechanisms with respect to their working principle, advantages, and drawbacks is given in[10].",
	"2.6. Ensemble of classifiers – motivation": "Single classifier makes error on different training samples. So, by creating an ensemble of classifiers and combining their outputs, the total error can be reduced and the detection accuracy can be increased. There are two main components in all ensemble sys- tems[53], viz., a strategy to build an ensemble that is as diverse as possible and the combination of outputs of classifier for the accurate classification decisions. Decision boundaries of each classifier have to be uniquely dif- ferent from others. To achieve this diversity, ensemble of classifiers can be constructed by manipulating training data, feature sets, and injecting randomness. For the construction of the ensemble, the entire dataset is divided into subsets and each classifier is trained with each subset. In order to construct the ensemble by manipulat- ing input feature sets, it is divided into smaller feature subsets and each classifier is trained with the same dataset. Another method to construct the ensemble is by randomly initializing the parameters such as weights, etc., and training with different parameter values at different times. As the number of features selected for training in this paper is less, the ensemble construction by feature set is not suitable[50]. The advantage of constructing an ensemble by manipulating training data is that the generated hypothesis per- forms fairly well even when there are only small changes in traffic data. So, ensemble construction by manipulating training data was chosen, as it would correctly detect the deviations, if any, however small it be. Classifier combination is divided into two categories: \u0002Classifier selection, where each classifier is trained to become an expert in some local area of the total feature space. \u0002Classifier fusion, where all classifiers are trained over the same feature space. Classifier outputs can be combined by methods such as Majority Voting[53], Weighted Majority Voting (WMV)[53], etc. In this pa- per, popular ensemble methods such as Bagging[16], Boosting [56], and AdaBoost[31]are compared with our proposal, RBPBoost. Our algorithm differs from existing algorithms in two ways, viz., achieving diversity of the classifiers and combining the classifier outputs through WMV and Weighted Product Rule (WPR)[53].",
	"3. Proposed system": "Eight Institutes/Universities (sites) situated in different geo- graphical locations are working collaboratively on a Smart and Secure Environment (SSE) project as shown inFig. 1. Our Institute (Site 4) is one among the sites connected through 2 Mbps Multi Protocol Label Switching (MPLS) Virtual Private Network (VPN) cloud. Each site maintains web, mail, DNS, and proxy servers. Unified Network Threat Management System (UNTMS) has been conceived by us, designed, and deployed in each site to monitor the real time traffic and to filter the malicious traffic. UNTMS 1330P.A. Raj Kumar, S. Selvakumar /Computer Communications 34 (2011) 1328–1341 consists of many modules such as Distributed Denial of Service (DDoS) attack detection module, Domain Name Server (DNS) Cache Poisoning detection module, Address Resolution Protocol (ARP) cache Poisoning detection module, Host Intrusion Detection System (HIDS) module, Network Intrusion Detection System (NIDS) module, and Anonymous Communication module, conceptualized by our subgroup of researchers. Our Distributed Denial of Service (DDoS) attack detection mod- ule analyzes the network traffic and classifies whether it is normal or malicious. Malicious traffic is identified and attack signatures are generated. The attack signature patterns are communicated to the peers (UNTMS) in the collaborative environment to enable the filters in UNTMS to drop the packets from the suspect (s), leading to the protection of critical services. Further, the proposed system is scalable because for every inclusion of additional collab- orating network, a deployment of UNTMS would suffice. Instead of building one centralized Intrusion Detection and Response System among the eight sites, co-operating autonomous agents can actively defend and maintain the integrity and trustworthiness of the system. The proposed architecture is shown inFig. 2. The pro- posed system consists of the following four stages: \u0002Data Collection (A). \u0002Preprocessing (B). \u0002Classification (C). \u0002Response (D).",
	"3.1. Data collection": "A receiver process running in promiscuous mode captures all incoming packets and stores in data storage server. The data is stored as set of traffic flows, with each instance being described by a set of features. Each instance is expressed in vector space model.",
	"3.2. Preprocessing": "Preprocessing refers to the process of extracting information about packet connections from data and construction of new statistical features. The preprocessing steps are explained as follows: \u0002Let ‘x’ be the input vector of dimension ‘n’, such thatx=[x 1 ,x 2 , x 3 ,...x n ]. The variablesx i of the input vector are the original features. \u0002Let ‘t x ’ be a vector of transformed features of dimension ‘t n ’. The statistical real time features of the packet for extraction are shown inTable 1. These features are used to find the statistical properties such as standard deviation and variance. These features quantify the behavioral characteristics of a connection in terms of number, type of various data items with respect to time. Hence, theses features are called as statistical real time features. Seven features are used as the gradients of the vector to classify the net- work pattern. Normalization is a process of ensuring that each attribute value in a database structure is suitable for further query- ing and free from certain undesirable characteristics. Hence, each variable is normalized in the range [\u00031,1] to eliminate the effect of scale difference. These values are used as inputs for machine learning algorithms. Our objective is to find out the dissimilarities, if any, between the patterns. This dissimilarity could be detected by a distance measure known as Euclidean distance[57]. Euclidean distance is defined as the sum of squares between the two clusters added up over all the variables. The Euclidean distance is Fig. 1.SSE environment. P.A. Raj Kumar, S. Selvakumar /Computer Communications 34 (2011) 1328–1341 1331 calculated as follows: The attributes are scaled to the range [\u00031, 1] using(1), where ‘i(t)’ denotes the value of the feature, ‘min (i)’ denotes the minimum value, and ‘max (i)’ denotes the maximum value. i norm ðtÞ¼ 2 \u0004 ½iðtÞ\u0003minðiÞ\u0005 maxðiÞ\u0003minðiÞ \u00031ð1Þ The data thus available for the classifier are real numbers be- tween\u00031 and 1. Further, the dissimilarity measure (d(x,y)) be- tween two vectorsxandyis calculated using(2). dð ~ x; ~ yÞ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi X N i¼1 ðx i \u0003y i Þ 2 r 2 i v u u t ð2Þ wherer i is the standard deviation of thex i .",
	"3.3. Proposed classification algorithm (RBPBoost)": "Block schematic of the RBPBoost is shown inFig. 3. Dataset of particular class is split into subsets. Each subset is trained with ensemble of classifiers and results are combined by WMV[53]. T K is the total number of classifiers chosen using cross-validation. Cross-validation is a popular method of manipulating training data to subdivide the training data into ‘k’ disjoint subsets and to recon- struct training sets by leaving out some of the subsets. Results of each classification system are further combined by WPR[53]. The efficiency of classification of the classifier is significant in the decision making process. Hence, it is measured by a parameter Q-statistic using(3). For effective decision, theQ-statistic should be zero. The training time depends on the number of times the classifier needs training which in turn depends on the mean square error between iterations reaching global minimum. The training is speeded up by removing the overlapping data and retaining only the training samples adjacent to the decision boundary. Q i;j ¼ðad\u0003scÞ=ðadþscÞð3Þ Q-statistic between two classifiers (iandj) is calculated using (3).‘ a’ is the number of samples that are correctly classified byi andj.‘ s’ is the number of samples that are correctly classified by iand incorrectly classified byj.‘ c’ is the number of samples that are incorrectly classified byiand correctly classified byj.‘d’is the number of samples that are incorrectly classified byiandj.A value ofQ= Zero or Positive is preferable, since it signifies the best classification by both the classifiers. A value ofQ= Negative indi- cates the misclassification which in turn will distort the decision making process, and hence it is not preferable.",
	"3.3.1. Training": "An ensemble of classifiers is trained for each individual data subset and the results are combined. A new classifier is added at each iteration. In our algorithm as given inFig. 4, two classes (Nor- mal and DDoS attack traffic) are considered. The inputs to the algo- rithm are as follows: \u0002Training data comprised of ‘n’ instances with correct output labels. \u0002Resilient Back Propagation algorithm (RBP) as supervised base classifier. \u0002Number of classifiers (T K Þ. From the experiments conducted, RBP emerged out as the best choice for deploying it as a learning algorithm for the base classifier due to its higher detection accuracy. The samples from each class are split into Data subsets. Samples from data subset are taken randomly with replacement and given as an input to the base classifier (RBP). The error e t of classifier is computed using (4). The error e t of classifierh t is weighted by the distribution, such that e t is the sum of distribution weights of the instances misclas- sified byh t . If the obtained error is more than the false alarm threshold, then the generated hypothesis is dropped and starts from Step 2.a as shown inFig. 4. Otherwise, the classifier is added to the Ensemble. Each classifier is assigned a weight as the loga- rithm of the reciprocal of its normalized error. Normalized error is calculated using (5). Classifier with small error has higher voting weight. Results of classifier are combined through WMV. The results of WMV are further combined through WPR. WPR has been analyzed theoretically in[39]and shown to be more effective in combining strong classifiers with less sensitive to the compound- ing effects of confidence errors upon combination, which justifies the usage of WPR in our proposed RBPBoost. D C B MPLS VPN Cloud Classifier Training Attack Attack Signature Normal Drop Packet Update FM Testing Incoming Network Traffic Filtering Module (FM) Drop Packet Online Database Offline Database Feature Extraction Normalization A Fig. 2.Architecture for DDoS attack detection and response system. Table 1 List of features. S. No. Feature description 1    Number of UDP echo packets to a specified port 2    Number of connections to the same host during specified time window 3    Number of ICMP echo reply packets from the same source 4    Number of connections that have SYN errors using the same service during specified time window 5    Number of connections having same window size, sequence number, and packet length 6    Number of packets in the URG flag set in TCP header 7    Type of service 1332P.A. Raj Kumar, S. Selvakumar /Computer Communications 34 (2011) 1328–1341",
	"3.3.2. Testing": "When a test instance is given as an input to RBPBoost algorithm, the votes for the instance corresponding to each ‘k’ data subset for a particular class are computed using WMV scheme on allT k clas- sifiers. These are further combined through WPR to obtain an aggregate vote for this instance.T kc is the number of classifiers cor- responding to thekth data subset andcth class. As the number of classes is 2, c is equal to 2. The number of classifiers through which test instance is run is given in(6). The output decision (attack or normal) of the classifiers is not final. The final decision is made using Neyman Pearson approach as described in Section3.3.3. X K k¼1 X L c¼1 T kc ð6Þ",
	"3.3.3. Neyman Pearson approach – cost minimization": "Neyman Pearson (NeP) – Structural Risk Minimization (SRM) [19]is an extension to NeP theory where prior knowledge of data distribution is not known. NeP hypothesis is useful in situations where different types of error have different consequences. Such applications include fraud detection, spam filtering, machine mon- itoring, target recognition, and disease diagnosis[19]. In most applications, class probabilities differ for training and testing data. But NeP does not assume prior knowledge of class probabilities. It automatically balances model complexity and training error. It is used to increase the detection accuracy rate with known maximum false alarm threshold ‘ l’ wherelis in the range [0,1]. The objective of using Neyman Pearson approach in this paper is to reduce the classification error costs. The cost minimization in NeP has the following steps: \u0002Calculation of total number of samples belonging to each class. \u0002Calculation of misclassified samples belonging to each class. \u0002Calculation of the optimum threshold and display of final clas- sification decision (Attack/ No Attack).",
	"3.3.3.1. Calculation oftotal number of samples for each class.The total": "number of samples from class j is calculated using(7). n j ¼ X n i¼1 IfY i ¼jgð7Þ LetZ n ={X i ,Y i } wherei=1,...,nbe a collection of ‘n’ indepen- dent and identically distributed samples ofZ=(X,Y). A learning algorithm is a mapping function,h n :Z n \u0003>H(X,Y), whereH(X, Y) is the set of all classifiers.h n is a rule for selecting a classifier based on training sample. ‘I’ denotes the indicator function.n j is the total number of samples for class ‘j’.",
	"3.3.3.2. Calculation of total number of misclassified samples for each": "class.To find the efficiency of classifier, the total number of mis- classified instances was calculated using(8). R j ðhÞ¼1=n j X i¼Y i ¼j IfhðiÞ–jgð8Þ R j (h) denotes the false positives corresponding toj=0,j=1.n j is the total number of samples for class ‘j’.Iis the indicator function which outputs either 0 (if the sample is correctly classified as classj)or1 (if the sample is not classified as classj). The number of misclassi- fied samples are summed and divided byn j , resulting in false alarms. Given a class of classifiersH, whereH 0 ={h2H:R 0 (h)6l}.",
	"3.3.3.3. Finding optimum threshold.A Receiver Operating Character-": "istic (ROC) curve is plotted against false positive (x-axis) and detec- tion accuracy (y-axis). The liney=xshows random guessing (half Fig. 4.RBPBoost classification algorithm. Data Source (Class1) Data Subset 1 ............ RBP_T 1 WMV WPR RBP_T K ... Data Subset n RBP_T 1 WMV RBP_T K ... Data Source (Class2) Data Subset 1 ............ RBP_T 1 WMV WPR RBP_T K ... Data Subset n RBP_T 1 WMV RBP_T K ... Neyman Pearson Approach (Cost Minimization) Classification Decision Fig. 3.Block schematic diagram of RBPBoost. P.A. Raj Kumar, S. Selvakumar /Computer Communications 34 (2011) 1328–1341 1333 of the samples are misclassified). If the misclassifications are more than 50%, the performance of Intrusion Detection system (IDS) will be poor. So, the default false positive decision threshold is chosen as 0.5. From the list of classifiers producing false positives, the classi- fier with the fewer false positives are considered as optimum threshold. Optimum threshold is calculated using(9). h \u0004 ¼argminfR j ðhÞ:h2H 0 gð9Þ New instance classification decision is based on the new optimum thresholdh \u0004 .h \u0004 is optimal with respect to classes of randomized tests/classifiers. Thus, the classification accuracy is improved by combining the outputs of different classifiers.",
	"3.4. Response system": "Detection system deployed in each site maintains a hash table and updates IP address and port number (attack signature) of the suspicious blacklist nodes. When a site receives the attack signa- ture, it checks if it exists in its hash table. If present, it means that the system is already alerted. If not, attack signature is added to the infected list. The updated attack signature is sent to all collaborat- ing nodes, to prevent any damage that may be caused to the avail- able services.",
	"3.5. Comparison of RBPBoost with the existing algorithms": "Comparison of RBPBoost classification algorithm with existing ensemble algorithms is shown inTable 2. Prior knowledge of data distribution is required only for Adaboost algorithm. The hypothe- ses are generated by training a weak classifier, using instances drawn from an iteratively updated distribution of the training data. The distribution update ensures that instances misclassified by the previous classifier are included in the training data of the next clas- sifier. Majority Voting is used to combine the ensemble of classifier outputs for Bagging, Adaboost, and RBPBoost. Boosting creates three weak classifiers. If first two classifiers agree on the same class, that class is the final classification decision. If these two clas- sifiers disagree, then class chosen by the third classifier is the final decision. The three classifiers are combined through a three-way majority vote. Our RBPBoost network is trained using the data source of each class consisting of ‘n’ number of data subsets. The traffic data from each subset are given as input to the neural classifier. Also, the ensemble in our approach is constructed by the training data. Dur- ing simulation experiments, it has been found that the detection accuracy was less as only 40% of the samples in the KDD cup dataset were used for training. The detection accuracy was increased to 90% as 70% of the samples were used for training. For DARPA datasets, the detection accuracy was less when only less than 50% of the samples were used for training, and the detection accuracy increased to 90% when 85% of the samples were given as input for training. So, large amount of traffic dataset is needed for training and validation, in order to achieve high detection accuracy in our proposed algorithm as shown inTable 2. As large amount of training dataset is used, overfitting is avoided which is an advantage of RBPBoost algorithm. In[71], proactive tests were conducted to identify and isolate the malicious traffic after successful TCP connection establishment. Majority Voting, Weighted Majority Voting, and Borda Count [53]are the three methods to combine the class labels of different classifiers. As assigning weights to instances have been considered in our RBPBoost algorithm, weighted majority voting is suitable. The votes are added up across all classifiers, and the class with the most votes is chosen as the ensemble decision. Different datasets lead to diverse individual neural network classifiers committing uncorrelated errors in the ensemble. Though individual classifiers may not take correct decision, voting is the solution to remove wrong decision made by individual classifier and to achieve high accuracy. For example, inFig. 3, each data sub- set of a particular class has ‘k’ number of classifiers. All ‘k’ classifi- ers are assigned weights during training. When a new instance is given as input, ‘k’ classifiers of data_subset1 outputs a class name whether it is an attack or normal. The weight corresponding to votes of attack class are summed and similarly the weight corre- sponding to the votes of normal class are summed. The class with more weights is chosen by WMV. Similarly, the classifier outputs of different data subsets of each class are done. There is a possibility for classifier weights for different classes to be the same in taking a decision during WMV. Hence, the WPR was used to combine the outputs of WMV of different data subsets of each class to increase the detection accuracy.",
	"4. Simulation results": "Simulations and the analysis of experimental data were per- formed with the use of MATLAB Neural Network Toolbox. The existing supervised and unsupervised algorithms were considered. The supervised algorithm attempts to learn some function with gi- ven input vector and actual output. In Unsupervised Learning, the algorithm attempts to learn only with given input vector by iden- tifying relationships among data. The unsupervised learning is dis- tinguished from supervised learning, where the inputs to the unsupervised algorithm are unlabeled samples or instances. Table 2 Comparison of existing ensemble of classification algorithms with proposed algorithm. Algorithm/featuresBaggingBoostingAdaBoostRBPBoost Prior knowledge of data distribution   Not requiredNot requiredRequiredNot required Method used to combine classifiers    Majority VotingThree-way Majority VoteWeighted Majority VotingWeighted Majority Voting and Weighted Product Rule. Number of classifiersGiven as inputThreeGiven as inputNumber of classes Data subset for Training operationDraws randomly some fraction from the Dataset Creates informative data subset Draws from the updated data distribution   Draws randomly some fraction from the Data Subset Classification error (cost) minimization NoNoNoYes (Neyman Pearson approach) DrawbacksWorks for small subset Limited to binary classification problems. Sensitive to noise and outliers Prior knowledge of data distribution needed before generating hypothesis. Frequent retraining needed Large amount of network traffic data is required AdvantagesSimple to implement with good performance Most informative dataset provided to each classifier Capable of handling multiclass and regression problems No indication of overfitting 1334P.A. Raj Kumar, S. Selvakumar /Computer Communications 34 (2011) 1328–1341 Though, it is intuitive that supervised algorithm would perform better than the unsupervised algorithms, we wanted to have a strong scientific basis for the selection of algorithm for base classi- fier. Accordingly, simulation experiments were conducted on RBP, SVM, K-Nearest Neighbor, Decision Tree, and K-Means Clustering. The KDD cup (1999) dataset[38]and DARPA traffic data, though old, have been used to test our algorithm against the existing ones in the literature. Further, we have generated DDoS attack in our lab and tested our RBPBoost algorithm.",
	"4.1. Experiment 1": "The algorithm with more detection accuracy and less false alarms is to be chosen as learning algorithm for the classifier. Supervised algorithms such as Multi Layer Perceptron-Resilient Back Propagation (MLP-RBP), Support Vector Machines (SVM), K-Nearest Neighbor, and Decision Trees were trained. KDD cup dataset used consisted of 4,898,430 connection records. Removing the duplicate records, the remaining traffic consisted of 812,813 normal connection records and 247,267 DoS connection records. Among these, 300,000 records comprising of both normal and DoS attack traffic were used for training the above listed algorithms. For the simulation experiments conducted, detection accuracy was calculated using (10). Accuracy¼ TPþTN TPþFPþTNþFN ð10Þ True Positive (TP) = Number of samples correctly predicted as attack class. False Positive (FP) = Number of samples incorrectly predicted as attack class. True Negative (TN) = Number of samples correctly predicted as normal class. False Negative (FN) = Number of samples incorrectly predicted as normal class. A three layerMLPneural network was simulated. The number of neurons in the input layer was 41 (features). Number of neurons in the output layer (sigmoid function) was 2. The optimal number of hidden neurons can be determined using the following rules of thumb in the literature: a. The number of hidden neurons should be two third of the size of the input layer plus the size of the output layer. b. The number of hidden neurons should be between the size of the input layer and the size of the output layer. c. The number of hidden neurons should be less than twice the size of the input layer. In our model, the size of the input layer is 7 and the size of the output layer is 2. According to Rule ‘a’, the number of hidden neu- rons is 7 (approx). According to Rule ‘b’, the number of hidden neu- rons is in between 2 and 7. According to Rule ‘c’, the number of hidden neurons is less than 14. From simulation experiments, we found that the number of hidden neurons was 20. So, it does not satisfy Rule ‘a’, ‘b’ and ‘c’. Existing techniques such as Bayesian Ying Yang method[64], hybrid optimization algorithm[52], dynamic node creation algo- rithm[12], statistical procedure[55], etc., were used for determin- ing the optimal number of hidden layer neurons. In Bayesian Ying Yang system, the optimal number of hidden neurons was deter- mined using probabilistic approach with minimized generalization error. But, in our algorithm, Bayesian or probabilistic analysis is not used for classification. So, Ying Yang method is not considered. In hybrid optimization algorithm, the decreasing relationship be- tween the sample approximation error and the number of hidden units is proven mathematically. In dynamic node creation algo- rithm, a critical value is chosen arbitrarily and when the training error is less than the critical value, a new node is being created in the hidden layer. This is done iteratively. In our algorithm, there is no prior critical value selection. Also, the capability of a specific architecture is evaluated only after training. Hence, this method of Dynamic node creation algorithm is not chosen in our algorithm. In statistical procedure, the method is executed in two phases, top down phase and bottom up phase. In bottom up phase, the parameters of neural models such as learning rate, etc., are esti- mated when increasing the number of hidden neurons. In top down phase, a selection among neural model is performed using statistical Fischer test. Our technique is similar to bottom up phase of Statistical Procedure. The parameters of neural models are esti- mated. But, despite using Statistical Fischer test, the optimal num- ber of hidden neurons is determined using Resilient Back Propagation technique with minimum generalization error. The number of hidden neurons which resulted in the minimum Gener- alization Error has been chosen as the optimal value in our algo- rithm. From the experimental studies, it was observed that setting more number of neurons in hidden layer resulted in Over- fitting and less number of neurons resulted in Underfitting. The learning rate parameter (L r Þdetermines how fast the sys- tem should adapt to new instances. From the experiments con- ducted and the results tabulated in[11], it was evident that lowerL r values produced less false positive rate and less detection accuracy. HigherL r values produced more false positive rates and stable detection accuracy. It was observed that the model with 20 neurons in hidden layer with learning rate = 0.2 produces more detection accuracy with less false alarms. C4.5 finds the normalized information gain for each feature. Objective is to minimize the number of nodes that produces mis- classifications. From the simulation experiments, the detection accuracy achieved for the best Decision Tree classifier was 95.3%. SVMperforms a mapping from the input space to higher dimen- sional feature space through the use of a kernel function. SVM model was trained on the training dataset. In our experiments, the kernel function used for SVM was Radial Basis function[33] which is a feed forward neural network. The clusters used during each simulation were 8, 16, 32, and 64. From the simulation, it was observed from[11]that the model with 20 neurons in hidden layer, 16 clusters, and learning rate = 0.1 performs best in terms of detection accuracy. K-Nearest Neighborclassifies a sample based on the majority vote of their nearest neighbors. The neighbors were identified with the representation of samples in multidimensional feature space. As it is binary classification problem, theKvalues vary in odd num- bers ranging 11, 21, 31, and 41. Simulation experiments were con- ducted and from the results tabulated in[11], it is evident that more detection accuracy was obtained whenk= 31. K-MeansClustering partitions ‘N’ samples in ‘k’ clusters with nearest mean. Simulations were carried out by varying the number of clusters ranging 2, 4, 8, 16, 32, and 128 and the results were tab- ulated in[11]. The simulated model that minimized the total squared error distance between each sample and center had 32 clusters. Fig. 5(in color) shows the output of the simulation in terms of confusion matrices. From the Figure, it is evident that during the training phase, the detection accuracy was 96.7% with 3.3% false positives and during the validation phase, the detection accuracy was 96.2% with 3.8% false positives. Further, it could be seen that during the testing phase, the detection accuracy was 98.1% with",
	"1.9% false positives.": "It is inferred that the trained network is able to generalize well and detect the new traffic patterns. In overall confusion matrix, the detection accuracy was 96.9% with 3.1% false positives. The outputs P.A. Raj Kumar, S. Selvakumar /Computer Communications 34 (2011) 1328–1341 1335 of the network are almost perfect (100%) with the high number of correct responses in the green squares and the low numbers of incorrect responses in the red squares. The lower right blue squares illustrate the overall accuracy. Similarly, the output for SVM, K-Nearest Neighbor, Decision Trees, K-Means Clustering in terms of confusion matrices are shown inFigs. 6–9. Fig. 10shows the colored lines in each axis representing the ROC curves. TheROC curveis a plot of the true positive rate (sensitivity) versus the false positive rate (1 – specificity) as the threshold is varied. A perfect test would show points in the upper-left corner, with 100% sensitivity and 100% specificity. From Fig. 10, it is observed that the network performs almost perfectly. From the simulation results shown inTable 3, it is evident that Multilayer Perceptron model outperforms the other algorithms with more detection accuracy.",
	"4.2. Experiment 2": "From Experiment 1, RBP was chosen as Base Classifier for con- structing an ensemble. Our proposed classification algorithm with cost minimization strategy is compared with existing ensemble methods[16,56,31]in terms of cost per sample on 1999 & 2000 Fig. 5.Confusion matrix for the Multilayer Perceptron model. Fig. 6.Confusion matrix for the Support Vector Machines. Fig. 7.Confusion matrix for the K-Nearest Neighbor. Fig. 8.Confusion matrix for the Decision Tree. 1336P.A. Raj Kumar, S. Selvakumar /Computer Communications 34 (2011) 1328–1341 DARPA datasets, Conficker dataset, and our own lab dataset. Three experiments were conducted with these three datasets and the re- sults are explained in Sections4.2.1, 4.2.2 and 4.2.3.",
	"4.2.1. Experiment 2.1": "The 1999 DARPA intrusion detection dataset[43]was used only for training the RBPBoost algorithm. Training data included ‘‘list files’’ that contained fields such as Start time, Duration, Protocol type, Source and Destination IP addresses, Source and Destination ports, and label to identify the class (attack or normal). These fields were used initially for training. Later during testing time, these fields were extracted from the connection records using tcptrace [61]and given to the classifier. The classifier produces the output as either attack or normal. System was designed in such a way that it is capable of learning the normal behavior through number of iterations in order to detect the attack and survive during an at- tack. 2000 DARPA intrusion detection specific dataset[44]had been used in our simulation during the test phase. It included a DDoS attack ran by an attacker with the use of more sophisticated attack tools. It contained LLDOS1.0 and LLDOS2.0.2 datasets whose attack time was 6 s and 8 s, respectively. The background traffic was the same as was used in the 1999 datasets. It was observed during the process of testing that the training error was less than the testing error. Hence, the variance was at minimum. Further, it was evident that the bias was at minimum. Simulation results were tabulated inTable 4. The results of exper- iments show that our RBPBoost algorithm is efficient enough for accurate detection of DDoS attacks. To facilitate performance com- parison among different ensemble methods, the cost function was used. Cost function is based on the number of samples that are misclassified. It was calculated using (11).kis the parameter for cost difference between false alarm and miss. The value ofkwas set as 6 for the experiments. If the cost is less, the performance of the detection system will be better. Cost¼ð1\u0003True positive rateÞþkðFalse positive rateÞð11Þ Fig. 11compares the results of our RBPBoost classification algo- rithm with the Bagging, Boosting, and AdaBoost ensemble meth- ods. It can be seen in our RBPBoost approach, that the cost per Fig. 9.Confusion matrix for the K-Means Clustering. Fig. 10.ROC curve for Multilayer Perceptron model. Table 3 Simulation results of supervised and unsupervised algorithm. ClassifierTrue Positive rate False Positive rate Multi Layer Perceptron (MLP)-Resilient Back Propagation",
	"4.2.2. Experiment 2.2": "The Conficker[17]dataset contains data from the UCSD Net- work Telescope for three days between November 2008 and Janu- ary 2009. The first day (21 November 2008) covers the onset of the Conficker A infection. On the second day, 21 December 2008, only Conficker A was active, and during the third and final day both Conficker A and B were active. The dataset contains 68 compressed pcap files each containing one hour of traces. The total size of the dataset for all the three days is 69 GB. The pcap files only contain packet headers; payload has been removed. Out of the 68 com- pressed pcap files, 20 compressed pcap files (only attack traffic) from three days and normal traffic from DARPA were used for training and testing. Fig. 12(in color) shows the ROC Plot of RBPBoost algorithm in terms of FPR on the horizontal axis and the TPR on the vertical axis. In the ROC plot, each blue marker (bubble) represents one oper- ating point. When moving over the plot, the gray cursor marker (light shaded bubble) follows the closest operating point. When er- ror minimization is attempted on one class, the error on the other at some moment inevitably increases. Optimal solution is found without class overlap. Simulation results are tabulated inTable 5. Till date, no results were published with the conficker dataset and hence unable to compare with our simulation result. From the results, it is evident that our proposed algorithm outperforms the existing algorithms using conficker dataset, in terms of TPR. However, it is also evident fromTable 5that the FPR of Boosting is less. Boosting algorithm provides the most informative training dataset for each classifier. The second classifier is trained in such a way that 50% of the samples are correctly classified and 50% of the samples are misclassified. Misclassified instances by first two classifiers are given as input to the third classifier. Though the ac- tual output of the sample is an attack, the decision is made by the third classifier if the first two classifiers disagree on their votes. So, the attack samples were misclassified and there is less chance of classifying the normal as an attack sample. Even though the perfor- mance of the boosting algorithm in terms of false positives is im- proved, the detection accuracy is less compared to RBPBoost approach. As our objective is towards increasing the detection accuracy and reducing false alarms, the cost metric based on the accuracy and false alarms is low compared to Boosting algorithm.",
	"4.2.3. Experiment 2.3": "The inspection of network traffic reveals confidential and per- sonal information, highly sensitive data, user’s network access pat- terns, etc. These confidential and personal information were anonymized and the header contents were removed before making it publicly available. So, the exact real attack traffic data were not made publicly available. This enabled us to create our own data- sets. So, normal and attack traffic data were created in our Smart and Secure Environment Project Laboratory. Attacks such as SYN flood, UDP flood (DNS Cache Poisoning), ICMP flood, and HTTP flood were generated in SSE Testbed. In order to evaluate the performance of RBPBoost algorithm, the SSE testbed shown inFig. 1was used. The environment that has been used for generating network traffic was similar to Planet Lab. SSE environment is described in Section3. Target machine was in Site 1. Client machines in all sites were used to generate both normal and attack traffic. In a single client machine, many vir- tual clients were created with spoofed and random IP addresses to generate both attack and normal traffic. HTTP traffic was generated using HTTP TrafficGen, a HTTP load generation tool. All client machines in the Intranet are connected through a backbone bandwidth of 1 Gbps and to different sites through a 2 Mbps MPLS VPN cloud. As Target (victim) server was available in Site 1, traces were collected in Site 1 in tcpdump format. For example, TCP port (80) traffic was generated by the clients in all sites including target server site. The traffic was collected during Fig. 12.ROC curve for RBPBoost algorithm (conficker dataset). Table 5 Simulation results of classification algorithms for conficker dataset. AlgorithmTrue Positive rateFalse Positive rateCost per sample Bagging90.64.00.334 Boosting93.43.20.258 AdaBoost96.83.80.260 RBPBoost97.23.60.244 1338P.A. Raj Kumar, S. Selvakumar /Computer Communications 34 (2011) 1328–1341 working hours. There were two types of traffic generated in the network, viz., legitimate and attack traffic. DDoS attack traffic with varying packet lengths were created using tools such as Netwag and TFN2K program. DDoS attack was launched on the Web server present in Site 1. Packets were captured from the network using Wireshark tool, which is based on the Libpcap library and in cap- ture mode, a filter was used to monitor traffic for WWW, TCP SYN, UDP, and IP. Tcpdump was used to extract the features from the captured packets of 1 s time window. Data obtained from fea- ture extraction were used for training the RBPBoost algorithm. Simulation results were tabulated inTable 6. The training samples were input to the RBPBoost algorithm, a few at a time, to make it learn incrementally during training. Our trained model was able to detect the variation of attack traffic pat- terns during testing. So, the proposed framework is suitable for detection of new attacks. From the simulation results, it is evident that our proposed RBPBoost algorithm outperforms the existing algorithm in terms of TPR. Moreover, it is also evident fromTable 6that the FPR of RBPBoost is less.Fig. 13depicts the cost per sam- ple for existing Ensemble algorithms and our RBPBoost algorithm. From the figure, it is seen that the cost per sample of RBPBoost algorithm is less compared to other existing Ensemble algorithms.",
	"4.3. Detection of new attacks": "In our simulation experiments, the dataset is split into training dataset and testing dataset. The testing dataset was served as com- pletely unseen samples to the trained ensemble. Testing dataset contains some attack types which were not included in the training dataset and which poses a challenge to test the ability of RBPBoost algorithm in detecting the new attack types. The performance of the ensemble of neural classifiers was evaluated based on the test- ing dataset. From the simulation experiments, it was evident that the trained ensembles were able to detect new attacks. Our RBPBoost algorithm was trained with DARPA 1999 dataset. DARPA 1999 dataset contains attacks such as back, land, mail- momb, Neptune, nmap, pod, smurf, icmp flood, syslog, and tear- drop. From DARPA 1999 dataset, attacks such as smurf and icmp flood were not considered for training. DARPA 2000 dataset con- tains attacks such as Trojan DDoS worm which is not present in DARPA 1999 dataset and were not considered during training. Hence, these attack traffic (unseen samples) were given as input during testing in order to test the capability of our RBPBoost algorithm. The trained ensemble was tested with DARPA 2000, Conficker dataset (unseen samples), and Lab dataset. The simulation results confirm that the detection rate was high and able to detect the new attacks. During learning, the instances that have not been properly learnt by the entire ensemble are assigned more weights. Hence, during next iteration, the instances that were assigned more weights or misclassified in the previous iteration are collected as a new dataset. A new instance of data is learnt incrementally to the trained ensemble as shown in Step 2 of RBPBoost Algorithm. The Learning Ensemble (LE) learns the new data without forgetting the previously acquired knowledge. So, a new instance of data is learnt without discarding the existing classifier and retraining a new one. Our SELF GENerating ENSemble (SELFGENS) detection process for new and old attacks in real time is shown inFig. 14 and the explanation for detection process is as follows: Ensemble of Classifiers trained with ‘n’ attacks is called Trained Ensemble (TE). For real time deployment, the TE model is repli- cated as Learning Ensemble (LE) and Stable Ensemble (SE). If traffic contains ‘n’ trained attack as input, it is detected by TE and passed through SE with the output of all the attacks being detected. If the network traffic contained ‘j’ new attacks other than the trained at- tacks and the normal traffic, then the traffic other than the trained ones are passed through LE while the trained ones take the path of TE-SE leading to the detection of trained attacks. LE learns using the new attack traffic and updates the SE which in turn updates TE, thus completing the learning of ‘j’ new attacks. Hence, Ensemble once trained does not require retraining in real time, instead learning on its own every time using the traffic other than trained ones. It is evident from the experiments that the RBPBoost algorithm classifies intrusions with more detection accuracy even when prior knowledge of data distribution is not known in advance and the number of instances in each class varies significantly. Thus, the proposed framework is suitable for real- time scenario for detecting the new attacks.",
	"5. Conclusion": "Critical services are often badly affected by DDoS attacks, in spite of the conventional deployment of network attack prevention mechanisms such as Firewall and Intrusion Detection Systems. Some intrusion detection systems detect only attacks with known signatures. Predicting the future attacks is impossible. Hence, the system must be trained and tested in such a way that it learns by observing the aberrant patterns associated with the network traffic and classify the incoming traffic as an attack or normal. The training time depends on the number of times the classifier needs training which in turn depends on the mean square error Table 6 Simulation results of classification algorithms for SSE dataset. AlgorithmTrue Positive rateFalse Positive rateCost per sample Bagging93.73.90.297 Boosting96.93.70.253 AdaBoost97.43.60.242 RBPBoost98.52.90.189"
}